{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Deadline**:  Sunday 21 November, 23.59.\n",
    "\n",
    "Your notebook should not give errors when executed with `Run All`. Please submit your answers via [Canvas](https://canvas.uva.nl/courses/25150/assignments/248822).\n",
    "\n",
    "| |Name |Student number|Email|\n",
    "|:-|:----|:-------------|:----|\n",
    "|1.|  |        |     |\n",
    "|2.|  |        |     |\n",
    "\n",
    "****Hand in the following****:\n",
    "* Your notebook. N.B. **click on `Kernel`, then `Restart & Run All`** before submitting, see notes.\n",
    "* A (printed) pdf version of your notebook.\n",
    "\n",
    "****NOTES****:\n",
    "* The assignment is a partial stand-in for a final examination, so the usual rules regarding plagiarism and fraud apply, with all attendant consequences. Code found on the internet or elsewhere is not acceptable as a solution.\n",
    "* Before submitting your work, **click on `Kernel`, then `Restart & Run All`** and verify that your notebook produces the desired results and does not error.\n",
    "* Make sure that any function you write has a docstring, and comments where appropriate.\n",
    "* Some questions require you to write code to obtain a numerical result (e.g., an option price). In that case, don't just give the function, but also the result of calling it with the given parameter values (i.e., the numerial value that it returns). If your function uses random numbers, then set the seed to 0 before calling it. This makes it much easier to grade the assignments (at least as long as the answer is correct).\n",
    "* How to convert your notebook to pdf: The easiest way is probably to use your browser's print functionality: e.g. in Chrome, press the three dots to go to Options, select 'Print...', and then select 'save as pdf' as Destination. I usually set it to 70% zoom such that the output fits the printed pdf pages.\n",
    "\n",
    "**Declaration of Originality**:\n",
    "\n",
    "We whose names are given under 1. and 2. above declare that\n",
    "1. These solutions are solely our own work.\n",
    "2. We have not made these solutions available to any other student."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1: Testing the CAPM\n",
    "The CAPM implies that\n",
    "\\begin{equation*}\n",
    "E(R_{i}-R_{f})=\\beta _{i}E(R_{m}-R_{f}),\\qquad \\beta _{i}=\\frac{\\mathrm{cov}%\n",
    "(R_{i},R_{m})}{\\mathrm{var}(R_{m})},\n",
    "\\end{equation*}\n",
    "\n",
    "where $R_i$ is the return on a stock, and $R_m$ is the market return. Suppose we have time series on $n$ different stock or portfolio returns $\\{R_{it},i=1,\\ldots ,n\\}_{t=1}^{T}$ and on a \"market return\" (value weighted index) $\\{R_{mt}\\}_{t=1}^{T}$.  We also have observations on a risk-free interest rate $\\{R_{ft}\\}_{t=1}^{T}$ and construct with these the excess returns $r_{it}=R_{it}-R_{ft}$ and $r_{mt}=R_{mt}-R_{ft}$. Now $\\beta_i$ can be estimated from the time-series regression \\begin{equation*}\n",
    "r_{it}=\\alpha _{i}+\\beta _{i}r_{mt}+\\varepsilon _{it},\\qquad t=1,\\ldots ,T.\n",
    "\\end{equation*}\n",
    "\n",
    "One way to test the CAPM is as follows: denote by $\\bar{r}_{i}$\n",
    "and $\\hat{\\beta}_{i}$ the average excess return and estimated $\\beta$ of stock $i$. If the model $E(r_{i})=\\beta_{i}E(r_{m})$ is valid, then $(\\hat{\\beta}_{i},\\bar{r}_{i})$ should lie on a line with zero intercept and slope $\\lambda =E(r_{mt})$. This line is called the *security market line*, and $\\lambda$ is known as the *market risk premium*.\n",
    "\n",
    "We can estimate $\\lambda $ by OLS in the cross-section regression\n",
    "\\begin{equation*}\n",
    "\\bar{r}_{i}=\\lambda \\hat{\\beta}_{i}+\\alpha _{i},\\qquad i=1,\\ldots ,n.\n",
    "\\end{equation*}\n",
    "Note that $\\hat{\\beta_i}$ is the regressor, $\\lambda$ the coefficient, and $\\alpha_i$ the error term.\n",
    "\n",
    "The assignment is to estimate the CAPM betas of the 30 constituent stocks of the Dow (using the return on the Dow as the market return, and the 3 month T-bill rate as the risk-free rate), then estimate the above cross-section regression, and finally make a plot of the security market line superimposed on a scatter plot of $(\\hat{\\beta}_{i},\\bar{r}_{i})$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.1** Import the relevant libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas_datareader.data as web\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import statsmodels.formula.api as smf\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.2** Obtain, from the FRED database, the daily adjusted closing prices of the Dow Jones Industrial Average (DJIA) from 31/12/2011 to 30/09/2021. Convert them into percentage log returns $r_t=100 \\times \\log(P_t/P_{t-1})$ and store them in a DataFrame `df_1`, which has the date as index and 'DJIA' as column name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = pd.DataFrame()\n",
    "startdate = pd.datetime(2011, 12, 31)\n",
    "enddate = pd.datetime(2021, 9, 30) \n",
    "df = web.DataReader('DJIA','fred', start=startdate, end=enddate)\n",
    "df_1 = 100*(np.log(df) - np.log(df.shift(1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.3** Obtain, also from the FRED database, daily data on the 3-month T-bill rate (DTB3) for the same period and divide them by 365:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DTB3 = pd.DataFrame()\n",
    "DTB = web.DataReader('DTB3','fred', start=startdate, end=enddate)\n",
    "DTB3 = DTB/365\n",
    "print(DTB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.4** The csv file `tickerdata.csv` which has been provided with this assignment contains the adjusted closing prices for the 30 constituent stocks of the Dow Jones.\n",
    "\n",
    "Import the dataset into a second DataFrame `df_2`, convert the `Date`-column to datetime, and make the `Date`-column the new index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv('/Applications/tickerdata.csv')\n",
    "df2['Date']= pd.to_datetime(df2['Date'])\n",
    "df2.set_index('Date', inplace=True)\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.5** Using a `for` loop (over the columns), convert all the given adjusted closing prices into percentage log returns $r_t=100\\log(P_t/P_{t-1})$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for returns in df_2:\n",
    "    returns = np.log(df2/df2.shift(1))\n",
    "df_2 = returns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.6** Concatenate DataFrames `df_1` and `df_2` along the common axis to a final DataFrame `df`:\n",
    "\n",
    "\n",
    "Notes (also hold for next question):\n",
    "* Need to specify the axis\n",
    "* `dtype` of the indices should be the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "returns=pd.concat([df_1,df_2],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.7** Convert the raw returns in `df` to excess returns by subtracting the `pandas` series `rf` from all columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "excess_returns = returns.sub(DTB3['DTB3'], axis = 'index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.8** Drop all rows from `df` that contain at least one NaN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "excess_returns = excess_returns.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.9** Use a `for` loop to estimate a CAPM time series regression for each stock, and store the estimated slope coefficient in a list. \n",
    "\n",
    "*Hint*: use string interpolation to construct the regression equation and use the list `tickers` below, containing the ticker symbols of all 30 constituent stocks of the DJIA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers = [\"AAPL\", \"AMGN\", \"AXP\", \"BA\", \"CAT\", \"CRM\", \"CSCO\", \"CVX\", \"DIS\", \"DD\",\n",
    "            \"GS\", \"HD\", \"HON\", \"IBM\", \"INTC\", \"JNJ\", \"JPM\", \"KO\", \"MCD\", \"MMM\", \n",
    "            \"MRK\", \"MSFT\", \"NKE\", \"PG\", \"TRV\", \"UNH\", \"V\", \"VZ\", \"WBA\",\"WMT\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list1 = []\n",
    "list2 = []\n",
    "\n",
    "for i in excess_returns:\n",
    "    if i != 'DJIA':\n",
    "        list1.append(i)\n",
    "        model = smf.ols('excess_returns[i]~ + DJIA',data=excess_returns)\n",
    "        result=model.fit(cov_type='HAC',cov_kwds={'maxlags':5})\n",
    "        list1.append(result.params[1])\n",
    "        list2.append(list1)\n",
    "        list1 = []\n",
    "print(list2)\n",
    "df4 = pd.DataFrame(list2, columns=['tickers', 'beta'])\n",
    "df4.set_index('tickers', inplace=True)\n",
    "print(df4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.10** Create a new dataframe that has `tickers` as index, and two columns: `beta`, containing the 30 estimated betas, and `meanret`, containing the mean excess returns of the 30 stocks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'excess_returns' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-49bb566bdb05>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlist3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mexcess_returns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'DJIA'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mlist1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'excess_returns' is not defined"
     ]
    }
   ],
   "source": [
    "list3 = []\n",
    "\n",
    "for i in excess_returns:\n",
    "    if i != 'DJIA':\n",
    "        list1.append(i)\n",
    "        list1.append(excess_returns[i].mean())\n",
    "        list3.append(list1)\n",
    "        list1 = []\n",
    "print(list3)\n",
    "df5 = pd.DataFrame(list3, columns=['tickers', 'meanret'])\n",
    "df5.set_index('tickers', inplace=True)\n",
    "\n",
    "df6=pd.concat([df4,df5],axis=1)\n",
    "\n",
    "print(df6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.11** Estimate the security market line by a cross-sectional regression (without intercept), and print a summary of the result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = smf.ols('beta~ -1 + meanret', data=df6)\n",
    "result=model.fit(cov_type='HAC',cov_kwds={'maxlags':5})\n",
    "print(result.summary2())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.12** Make a scatter plot of $(\\hat{\\beta}_{i},\\bar{r}_{i})$ and overlay it with a red regression line (the security market line). Add a title and legend, and label the axes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-3251781b2f7f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf6\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'beta'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf6\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'meanret'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'o'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolyfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf6\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'beta'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf6\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'meanret'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf6\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'beta'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mdf6\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'beta'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'beta'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mean excess returns'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "plt.plot(df6['beta'], df6['meanret'], 'o')\n",
    "m, b = np.polyfit(df6['beta'],df6['meanret'], 1)\n",
    "plt.plot(df6['beta'], m*df6['beta'] + b, 'r-')\n",
    "plt.xlabel('beta')\n",
    "plt.ylabel('mean excess returns')\n",
    "plt.title('Down Jones')\n",
    "plt.legend(['individual stock', 'security market line'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2: Value at Risk\n",
    "In this question we construct a VaR estimates for two stocks, one high risk and one low risk stock. Further, for the high risk stock, we split the sample into two periods to evaluate the VaR out-of-sample. You can re-use the data from the previous question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.1** Use the above estimates to identify the most risky and the least risky stock in terms of their estimated betas. Create two `pandas` series `r_hirisk` and `r_lorisk` from the `df` DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.2** For both stocks, create a 1% VaR estimate, assuming a $t$ distribution. Comment on the difference between the estimates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer the following questions for the *risky stock* only.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.3** Test the fit of the Student's *t* distribution using a QQ plot, and give a conclusion in words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.4** Make a plot consisting of two subplots, the left of which shows $-R_t$ and $VaR^{0.01}$, and the right panel showing a histogram of $R_t$ overlaid with the fitted Student's *t* distribution. Make sure to add title, legend, and axis labels.\n",
    "\n",
    "*Hint*: The Value at Risk $VaR^{0.01}$ is constant over time, so the plot of the VaR will be a horizontal line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.5** Finally, split the sample of `r_hirisk` into two parts: one sample from 2012-2019, and one sample from 2020-2021. Use the first sample (2012-2019) to compute the 1% VaR assuming a Student's $t$ distribution as before. Then, use the second sample to evaluate the VaR by counting the number of exceedances in the period 2020-2021. Give a conclusion in words.\n",
    "\n",
    "*Bonus* Does your conclusion change if you evaluate the VaR based on returns in 2021 only?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
